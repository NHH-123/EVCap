(/workspace/env_evcap) root@02b705b52203:/workspace/EVCap# python evaluation/cocoeval.py --result_file_path results/eval_evcap_coco/coco*.json |& tee -a  coco_generated_captions.json
PTBTokenizer tokenized 307085 tokens at 710646.54 tokens per second.
PTBTokenizer tokenized 59031 tokens at 292166.23 tokens per second.
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/workspace/EVCap/evaluation/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value
WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ...
done [0.5 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].
Threads( StanfordCoreNLP ) [21.168 seconds]
Warning: Nashorn engine is planned to be removed from a future JDK release
SPICE evaluation took: 34.40 s
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 48709, 'reflen': 48112, 'guess': [48709, 43709, 38709, 33709], 'correct': [39845, 24010, 13036, 6767]}
ratio: 1.012408546724289
Bleu_1: 0.818
Bleu_2: 0.670
Bleu_3: 0.533
Bleu_4: 0.417
computing METEOR score...
METEOR: 0.312
computing Rouge score...
ROUGE_L: 0.610
computing CIDEr score...
CIDEr: 1.400
computing SPICE score...
SPICE: 0.246
Bleu_1: 0.818
Bleu_2: 0.670
Bleu_3: 0.533
Bleu_4: 0.417
METEOR: 0.312
ROUGE_L: 0.610
CIDEr: 1.400
SPICE: 0.246